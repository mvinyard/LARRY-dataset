{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, json, pickle, scipy.sparse, sys, scipy.sparse as ss\n",
    "from helper_functions_py3 import *\n",
    "from sklearn.preprocessing import normalize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = ss.load_npz('counts_norm.npz')\n",
    "lk_lsk = np.load('lk_lsk.npy')\n",
    "tps_flat = np.load('tps_flat.npy')\n",
    "gene_list = load_genes('genes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fate_names = open('FINAL_fate_names.txt').read().split('\\n')\n",
    "BMq = np.load('BMq.npy')\n",
    "mpp_ff = np.array([x.decode('utf-8') for x in lk_lsk[tps_flat==2]])=='LSK'\n",
    "BM_ff = np.all([BMq.sum(1)>0, mpp_ff],axis=0)\n",
    "Y = BMq[BM_ff,:] / BMq[BM_ff,:].sum(1)[:,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2 = E[tps_flat==2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = filter_genes(E2[mpp_ff,:],3,3,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFs = [l.split('\\t')[2] for l in open('tf_list.txt').read().split('\\n')]\n",
    "TFs = np.array([gene_list.index(g) for g in TFs if g in gene_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFE = [l.split('\\t')[1] for l in open('enriched_genes_IN_VITRO.txt').read().split('\\n')]\n",
    "DFE = np.array([gene_list.index(g) for g in DFE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose best hyper for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accs = []\n",
    "for i,gene_ff in enumerate([[],TFs, DFE, gf]):\n",
    "    if len(gene_ff)==0: gene_ff = np.random.randint(0,len(gene_list),len(TFs))\n",
    "    EE = E2[BM_ff,:][:,gene_ff]\n",
    "        \n",
    "    accs = []\n",
    "    rr = np.random.uniform(0,1,BM_ff.sum())\n",
    "    train = rr < .5\n",
    "    test = rr > .5\n",
    "    for jj,C in enumerate(np.logspace(-3,3,14)):\n",
    "        LR = LogisticRegression(C=C)\n",
    "        LR.fit(EE[train,:],np.argmax(Y[train,:],axis=1))\n",
    "        YY = LR.predict(EE[test,:])\n",
    "        accs.append(np.mean(np.argmax(Y[test,:],axis=1)==YY))\n",
    "    all_accs.append(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in all_accs:\n",
    "    plt.plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in all_accs:\n",
    "    plt.plot(acc)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Log regularization (C)')\n",
    "plt.plot([2]*2,[0.35,.62],'--k')\n",
    "plt.xticks(range(14)[::2], [round(x,1) for x in np.linspace(-3,3,14)][::2]);\n",
    "plt.gcf().set_size_inches((4,3))\n",
    "plt.savefig('RG_reg_scan.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose best params for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.random.uniform(0,1,BM_ff.sum())\n",
    "test = np.random.uniform(0,1,BM_ff.sum()) > .5\n",
    "train = np.logical_not(test)\n",
    "\n",
    "all_accs = []\n",
    "all_layer_nums = [(100,20)] #(100,50 ,20),(200,50 ,20), (50 ,50 ,20),(200,100,20),(200,50), \n",
    "                  #(200,100),(200,20),(100,50),(100,20),(200,100,50,20)]\n",
    "for i,gene_ff in enumerate([[],TFs, DFE, gf]):\n",
    "    if len(gene_ff)==0: gene_ff = np.random.randint(0,len(gene_list),len(TFs))\n",
    "    EE = E2[BM_ff,:][:,gene_ff]\n",
    "    accs = np.zeros((10,8))\n",
    "    for ii,layer_nums in enumerate(all_layer_nums):\n",
    "        for jj,alpha in enumerate(np.logspace(-3,1,8)): \n",
    "            print(ii,jj)\n",
    "            MLP = MLPClassifier(hidden_layer_sizes=layer_nums, max_iter=100000, alpha=alpha)\n",
    "            MLP.fit(EE[train,:],np.argmax(Y[train,:],axis=1))\n",
    "            YY = MLP.predict(EE[test,:])\n",
    "            accs[ii,jj] = np.mean(np.argmax(Y[test,:],axis=1)==YY)\n",
    "    \n",
    "    all_accs.append(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_nums = [(100,50 ,20),(200,50 ,20), (50 ,50 ,20),(200,100,20),(200,50), \n",
    "                  (200,100),(200,20),(100,50),(100,20),(200,100,50,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accs = np.array(all_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.plot(all_accs[i][0,2:])\n",
    "plt.xticks(range(6), [round(x,2) for x in np.linspace(-3,1,8)[2:]]);\n",
    "plt.plot([3]*2,[0.38,.57],'--k')\n",
    "plt.xlabel('Log regularization (alpha)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.gcf().set_size_inches((4,3))\n",
    "plt.savefig('NN_reg_scan.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = np.zeros((100,4,2))\n",
    "for i,gene_ff in enumerate([[],TFs, DFE, gf]): #TFs, gf, np.ones(len(gene_list))>0]):\n",
    "    if len(gene_ff)==0: gene_ff = np.random.randint(0,len(gene_list),len(TFs))\n",
    "    EE = E2[BM_ff,:][:,gene_ff].toarray()\n",
    "    print(i)\n",
    "    #if i < 3: continue\n",
    "    for ii in range(100):\n",
    "\n",
    "        rr = np.random.uniform(0,1,BM_ff.sum())\n",
    "        train = rr < .75\n",
    "        test = rr > .75\n",
    "        \n",
    "        LR = LogisticRegression(C= 8.37677640e-03, max_iter=100)\n",
    "        LR.fit(EE[train,:],np.argmax(Y[train,:],axis=1))\n",
    "        YY = LR.predict(EE[test,:])\n",
    "        acc[ii,i,0] = np.mean(np.argmax(Y[test,:],axis=1)==YY)\n",
    "\n",
    "        MLP = MLPClassifier(hidden_layer_sizes=(100, 20), alpha=.01, activation='relu', solver='adam', momentum=0.9)\n",
    "        MLP.fit(EE[train,:],np.argmax(Y[train,:],axis=1))\n",
    "        YY = MLP.predict(EE[test,:])\n",
    "        acc[ii,i,1] = np.mean(np.argmax(Y[test,:],axis=1)==YY)\n",
    "        \n",
    "        print(acc[ii,i,:])\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.mean(acc,axis=0)\n",
    "Xerr = np.std(acc,axis=0)\n",
    "plt.errorbar(range(4),X[:,0],yerr=Xerr[:,0]/2,fmt='o', capsize=2, ms=4)\n",
    "plt.errorbar(np.arange(4)+.2,X[:,1],yerr=Xerr[:,1]/2,fmt='o', capsize=2, ms=4)\n",
    "plt.xticks(range(4))\n",
    "plt.xlim([-.25,3.35])\n",
    "plt.ylim([.38,0.64])\n",
    "plt.gcf().set_size_inches((2.5*.9,2*.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, ttest_ind\n",
    "mm = []\n",
    "for i in range(4):\n",
    "    print(mannwhitneyu(acc[:,i,0],acc[:,i,1])[1])\n",
    "    mm.append(acc[:,i,1].mean()/acc[:,i,0].mean()-1)\n",
    "print(np.mean(mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(mannwhitneyu(acc[:,i,:].flatten(),acc[:,i+1,:].flatten())[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moseq2)",
   "language": "python",
   "name": "moseq2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
